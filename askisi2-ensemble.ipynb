{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2.1 Objective\n\r\nTo perform a comprehensive exploratory data analysis (EDA) on the HelpSteer Dataset to\r\nunderstand the data's characteristics and attribute correlations.\r","metadata":{}},{"cell_type":"code","source":"!pip install datasets\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:20.398834Z","iopub.execute_input":"2024-11-16T13:32:20.399147Z","iopub.status.idle":"2024-11-16T13:32:32.939779Z","shell.execute_reply.started":"2024-11-16T13:32:20.399109Z","shell.execute_reply":"2024-11-16T13:32:32.938586Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\n# Load the dataset splits\ndataset = load_dataset(\"nvidia/HelpSteer\")\ntrain_df = pd.DataFrame(dataset['train'])\nvalidation_df = pd.DataFrame(dataset['validation'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:32.942400Z","iopub.execute_input":"2024-11-16T13:32:32.943201Z","iopub.status.idle":"2024-11-16T13:32:41.793068Z","shell.execute_reply.started":"2024-11-16T13:32:32.943152Z","shell.execute_reply":"2024-11-16T13:32:41.792190Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/7.96k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4f2e3d10a184604af6a1c79706b1e6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl.gz:   0%|          | 0.00/15.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06ee5bbdb96c4af5953db92f2b7e4f41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation.jsonl.gz:   0%|          | 0.00/813k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a507b864efc14f118773889a9f613b13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/35331 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a78c3fe70ce449548fd8754d17fb6ca8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1789 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c7675b2af2b414387eb4be18daf2755"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:41.794204Z","iopub.execute_input":"2024-11-16T13:32:41.794714Z","iopub.status.idle":"2024-11-16T13:32:41.812398Z","shell.execute_reply.started":"2024-11-16T13:32:41.794678Z","shell.execute_reply":"2024-11-16T13:32:41.811521Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  What are the three most important things to co...   \n1  What are the three most important things to co...   \n2  What are the three most important things to co...   \n3  What are the three most important things to co...   \n4  Background:\\n<start of reference>\\nFamily doct...   \n\n                                            response  helpfulness  \\\n0  To build an assistive device to help an elderl...            3   \n1  There are many different types of assistive de...            4   \n2  When deciding what technology to use to build ...            4   \n3  You can create an assistant device to help an ...            3   \n4  Hi there! I'm Dr. Family, and I'm here to tell...            3   \n\n   correctness  coherence  complexity  verbosity  \n0            4          4           2          2  \n1            3          3           2          3  \n2            4          4           2          2  \n3            3          3           2          3  \n4            3          3           2          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>response</th>\n      <th>helpfulness</th>\n      <th>correctness</th>\n      <th>coherence</th>\n      <th>complexity</th>\n      <th>verbosity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are the three most important things to co...</td>\n      <td>To build an assistive device to help an elderl...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What are the three most important things to co...</td>\n      <td>There are many different types of assistive de...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What are the three most important things to co...</td>\n      <td>When deciding what technology to use to build ...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What are the three most important things to co...</td>\n      <td>You can create an assistant device to help an ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Background:\\n&lt;start of reference&gt;\\nFamily doct...</td>\n      <td>Hi there! I'm Dr. Family, and I'm here to tell...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"validation_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:41.814558Z","iopub.execute_input":"2024-11-16T13:32:41.815122Z","iopub.status.idle":"2024-11-16T13:32:41.826555Z","shell.execute_reply.started":"2024-11-16T13:32:41.815076Z","shell.execute_reply":"2024-11-16T13:32:41.825609Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  The reference text below provides context for ...   \n1  The reference text below provides context for ...   \n2  The following information may be useful:\\n<sta...   \n3  The following information may be useful:\\n<sta...   \n4  The following information may be useful:\\n<sta...   \n\n                                            response  helpfulness  \\\n0  A woman who helped her cousin retrieve her bel...            3   \n1  A woman who tried to help her cousin retrieve ...            2   \n2  The protagonist has a very casual attitude tow...            3   \n3  The protagonist has a positive attitude toward...            3   \n4  The protagonist's attitude toward swear words ...            3   \n\n   correctness  coherence  complexity  verbosity  \n0            2          3           2          2  \n1            2          3           1          2  \n2            2          3           1          1  \n3            3          3           2          1  \n4            3          3           2          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>response</th>\n      <th>helpfulness</th>\n      <th>correctness</th>\n      <th>coherence</th>\n      <th>complexity</th>\n      <th>verbosity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The reference text below provides context for ...</td>\n      <td>A woman who helped her cousin retrieve her bel...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The reference text below provides context for ...</td>\n      <td>A woman who tried to help her cousin retrieve ...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The following information may be useful:\\n&lt;sta...</td>\n      <td>The protagonist has a very casual attitude tow...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The following information may be useful:\\n&lt;sta...</td>\n      <td>The protagonist has a positive attitude toward...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The following information may be useful:\\n&lt;sta...</td>\n      <td>The protagonist's attitude toward swear words ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:41.827636Z","iopub.execute_input":"2024-11-16T13:32:41.827942Z","iopub.status.idle":"2024-11-16T13:32:41.865927Z","shell.execute_reply.started":"2024-11-16T13:32:41.827911Z","shell.execute_reply":"2024-11-16T13:32:41.865077Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 35331 entries, 0 to 35330\nData columns (total 7 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   prompt       35331 non-null  object\n 1   response     35331 non-null  object\n 2   helpfulness  35331 non-null  int64 \n 3   correctness  35331 non-null  int64 \n 4   coherence    35331 non-null  int64 \n 5   complexity   35331 non-null  int64 \n 6   verbosity    35331 non-null  int64 \ndtypes: int64(5), object(2)\nmemory usage: 1.9+ MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_df[\"complexity\"].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:41.867051Z","iopub.execute_input":"2024-11-16T13:32:41.867740Z","iopub.status.idle":"2024-11-16T13:32:41.880131Z","shell.execute_reply.started":"2024-11-16T13:32:41.867697Z","shell.execute_reply":"2024-11-16T13:32:41.879371Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"count    35331.000000\nmean         1.443888\nstd          0.822268\nmin          0.000000\n25%          1.000000\n50%          1.000000\n75%          2.000000\nmax          4.000000\nName: complexity, dtype: float64"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# 3.1 Objective\n\nDevelop a regression model capable of reasonably accurately predicting the complexity\nattribute of a response using the HelpSteer Dataset.","metadata":{}},{"cell_type":"markdown","source":"Use a small model like DistilBERT to extract embeddings from the prompt and response columns","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:41.881075Z","iopub.execute_input":"2024-11-16T13:32:41.881368Z","iopub.status.idle":"2024-11-16T13:32:45.130124Z","shell.execute_reply.started":"2024-11-16T13:32:41.881337Z","shell.execute_reply":"2024-11-16T13:32:45.128922Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertModel\n\n# Load the model and tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)  # Move model to GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:45.131275Z","iopub.execute_input":"2024-11-16T13:32:45.131620Z","iopub.status.idle":"2024-11-16T13:32:49.918153Z","shell.execute_reply.started":"2024-11-16T13:32:45.131561Z","shell.execute_reply":"2024-11-16T13:32:49.917304Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f47b3254e1b34da49aaf3398a248b0ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a95107083544a21b920b92232507a50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93fd626639f4efca45f7aa14b421dd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f519f894ddee487c8a4df60cc38a67a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b278c7494e41c8a8f8863bf3482ccb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"461b20bad9894cd3907791dcfb9a22b7"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":" Tokenize the input text, passes it through the model, and returns the embeddings","metadata":{}},{"cell_type":"code","source":"def get_embeddings(text):\n    # Tokenize the input text and send it to the GPU\n    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n    \n    # Generate embeddings with no gradient tracking\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # Move embeddings back to CPU for further processing if necessary\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n    return embeddings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:49.919374Z","iopub.execute_input":"2024-11-16T13:32:49.919915Z","iopub.status.idle":"2024-11-16T13:32:49.925813Z","shell.execute_reply.started":"2024-11-16T13:32:49.919879Z","shell.execute_reply":"2024-11-16T13:32:49.924843Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Apply this function to both the prompt and response columns","metadata":{}},{"cell_type":"code","source":"train_df['prompt_embedding'] = train_df['prompt'].apply(get_embeddings)\ntrain_df['response_embedding'] = train_df['response'].apply(get_embeddings)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:32:49.929398Z","iopub.execute_input":"2024-11-16T13:32:49.930050Z","iopub.status.idle":"2024-11-16T13:50:43.688939Z","shell.execute_reply.started":"2024-11-16T13:32:49.930015Z","shell.execute_reply":"2024-11-16T13:50:43.688046Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import numpy as np\n\n# Average the prompt and response embeddings\ntrain_df['combined_embedding'] = train_df.apply(lambda row: (row['prompt_embedding'] + row['response_embedding']) , axis=1)\n\n\n# Prepare the feature matrix (X) and target variable (y)\nX = np.vstack(train_df['combined_embedding'].values)\ny = train_df['complexity'].values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:50:43.690028Z","iopub.execute_input":"2024-11-16T13:50:43.690318Z","iopub.status.idle":"2024-11-16T13:50:44.488201Z","shell.execute_reply.started":"2024-11-16T13:50:43.690281Z","shell.execute_reply":"2024-11-16T13:50:44.487391Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_df['combined_embedding']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:50:44.490110Z","iopub.execute_input":"2024-11-16T13:50:44.490499Z","iopub.status.idle":"2024-11-16T13:50:44.505551Z","shell.execute_reply.started":"2024-11-16T13:50:44.490454Z","shell.execute_reply":"2024-11-16T13:50:44.504689Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0        [-0.4473592, 0.56709456, 0.3154971, -0.0720754...\n1        [-0.5759791, 0.607692, 0.2765418, -0.09543538,...\n2        [-0.67710173, 0.4798023, 0.25830466, -0.029011...\n3        [-0.53883135, 0.4674706, 0.37658167, 0.0036770...\n4        [0.0087714195, 0.64115447, 0.36642605, -0.2480...\n                               ...                        \n35326    [-1.5298746, -0.370573, 0.47147185, -0.2574832...\n35327    [-0.47161123, 0.105901666, 0.08467649, -0.0057...\n35328    [-0.34656668, -0.09481117, 0.19014813, 0.02840...\n35329    [0.27400887, 0.114452496, 0.00477916, 0.052146...\n35330    [-0.39414436, -0.123563945, 0.34819585, 0.0215...\nName: combined_embedding, Length: 35331, dtype: object"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"train_df['combined_embedding'].info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:50:44.506759Z","iopub.execute_input":"2024-11-16T13:50:44.507084Z","iopub.status.idle":"2024-11-16T13:50:44.524410Z","shell.execute_reply.started":"2024-11-16T13:50:44.507052Z","shell.execute_reply":"2024-11-16T13:50:44.523556Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.series.Series'>\nRangeIndex: 35331 entries, 0 to 35330\nSeries name: combined_embedding\nNon-Null Count  Dtype \n--------------  ----- \n35331 non-null  object\ndtypes: object(1)\nmemory usage: 276.1+ KB\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"sample_embedding_shape = train_df['combined_embedding'].iloc[0].shape\nprint(\"Sample embedding shape:\", sample_embedding_shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:50:44.525470Z","iopub.execute_input":"2024-11-16T13:50:44.525795Z","iopub.status.idle":"2024-11-16T13:50:44.534966Z","shell.execute_reply.started":"2024-11-16T13:50:44.525763Z","shell.execute_reply":"2024-11-16T13:50:44.534106Z"}},"outputs":[{"name":"stdout","text":"Sample embedding shape: (768,)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# X is the feature matrix (e.g., combined embeddings), y is the target (complexity)\nX = np.vstack(train_df['combined_embedding'].values)  \ny = train_df['complexity'].values\n\n# Split the data into 80% training and 20% testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:50:44.535976Z","iopub.execute_input":"2024-11-16T13:50:44.536251Z","iopub.status.idle":"2024-11-16T13:50:45.301391Z","shell.execute_reply.started":"2024-11-16T13:50:44.536220Z","shell.execute_reply":"2024-11-16T13:50:45.300516Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(\"Training set:\", X_train.shape, y_train.shape)\nprint(\"Testing set:\", X_test.shape, y_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:50:45.302551Z","iopub.execute_input":"2024-11-16T13:50:45.303119Z","iopub.status.idle":"2024-11-16T13:50:45.309714Z","shell.execute_reply.started":"2024-11-16T13:50:45.303084Z","shell.execute_reply":"2024-11-16T13:50:45.308764Z"}},"outputs":[{"name":"stdout","text":"Training set: (28264, 768) (28264,)\nTesting set: (7067, 768) (7067,)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T13:50:45.310883Z","iopub.execute_input":"2024-11-16T13:50:45.311230Z","iopub.status.idle":"2024-11-16T13:50:45.318644Z","shell.execute_reply.started":"2024-11-16T13:50:45.311196Z","shell.execute_reply":"2024-11-16T13:50:45.317851Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(28264, 768)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"from sklearn.ensemble import StackingRegressor\nfrom sklearn.linear_model import Ridge\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# Base models with GPU support\nbase_models = {\n    'xgboost': XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42, tree_method='gpu_hist'),\n    'lightgbm': LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42, device='gpu'),\n}\n\n# Train each base model with tqdm and GPU\nbase_predictions = {}\nfor name, model in tqdm(base_models.items(), desc=\"Training Base Models on GPU\"):\n    model.fit(X_train, y_train)\n    base_predictions[name] = model.predict(X_test)\n\n# Combine predictions from base models as features for the meta-model\nmeta_features = np.column_stack(list(base_predictions.values()))\n\n# Meta-model (still on CPU for simplicity)\nmeta_model = Ridge(alpha=1.0)\n\n# Train the meta-model with tqdm\nwith tqdm(total=1, desc=\"Training Meta-Model\") as pbar:\n    meta_model.fit(meta_features, y_test)\n    pbar.update(1)\n\n# Final predictions\ny_pred = meta_model.predict(meta_features)\n\n# Evaluate the ensemble model\nrmse = mean_squared_error(y_test, y_pred, squared=False)\nmae = mean_absolute_error(y_test, y_pred)\n\nprint(f\"\\nMean Absolute Error (MAE): {mae}\")\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-16T14:35:22.057449Z","iopub.execute_input":"2024-11-16T14:35:22.057816Z","iopub.status.idle":"2024-11-16T14:35:41.689086Z","shell.execute_reply.started":"2024-11-16T14:35:22.057783Z","shell.execute_reply":"2024-11-16T14:35:41.687889Z"}},"outputs":[{"name":"stderr","text":"Training Base Models on GPU:   0%|          | 0/2 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:35:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:35:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:35:25] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\nTraining Base Models on GPU:  50%|█████     | 1/2 [00:03<00:03,  3.66s/it]","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] This is the GPU trainer!!\n[LightGBM] [Info] Total Bins 195840\n[LightGBM] [Info] Number of data points in the train set: 28264, number of used features: 768\n[LightGBM] [Info] Using GPU Device: Tesla P100-PCIE-16GB, Vendor: NVIDIA Corporation\n[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n","output_type":"stream"},{"name":"stderr","text":"1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] GPU programs have been built\n[LightGBM] [Info] Size of histogram bin entry: 8\n[LightGBM] [Info] 768 dense feature groups (20.70 MB) transferred to GPU in 0.018351 secs. 0 sparse feature groups\n[LightGBM] [Info] Start training from score 1.439251\n","output_type":"stream"},{"name":"stderr","text":"Training Base Models on GPU: 100%|██████████| 2/2 [00:19<00:00,  9.79s/it]\nTraining Meta-Model: 100%|██████████| 1/1 [00:00<00:00, 46.03it/s]","output_type":"stream"},{"name":"stdout","text":"\nMean Absolute Error (MAE): 0.5180972612314204\nRoot Mean Squared Error (RMSE): 0.6425749929200665\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21}]}