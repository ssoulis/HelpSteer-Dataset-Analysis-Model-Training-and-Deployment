{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2.1 Objective\n\r\nTo perform a comprehensive exploratory data analysis (EDA) on the HelpSteer Dataset to\r\nunderstand the data's characteristics and attribute correlations.\r","metadata":{}},{"cell_type":"code","source":"!pip install datasets\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:40:46.191154Z","iopub.execute_input":"2024-11-19T13:40:46.191965Z","iopub.status.idle":"2024-11-19T13:40:55.798914Z","shell.execute_reply.started":"2024-11-19T13:40:46.191912Z","shell.execute_reply":"2024-11-19T13:40:55.798018Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from datasets import load_dataset\nimport pandas as pd\n\n# Load the dataset splits\ndataset = load_dataset(\"nvidia/HelpSteer\")\ntrain_df = pd.DataFrame(dataset['train'])\nvalidation_df = pd.DataFrame(dataset['validation'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:40:55.800788Z","iopub.execute_input":"2024-11-19T13:40:55.801091Z","iopub.status.idle":"2024-11-19T13:41:00.690967Z","shell.execute_reply.started":"2024-11-19T13:40:55.801062Z","shell.execute_reply":"2024-11-19T13:41:00.689997Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:00.692070Z","iopub.execute_input":"2024-11-19T13:41:00.692405Z","iopub.status.idle":"2024-11-19T13:41:00.705403Z","shell.execute_reply.started":"2024-11-19T13:41:00.692369Z","shell.execute_reply":"2024-11-19T13:41:00.704398Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  What are the three most important things to co...   \n1  What are the three most important things to co...   \n2  What are the three most important things to co...   \n3  What are the three most important things to co...   \n4  Background:\\n<start of reference>\\nFamily doct...   \n\n                                            response  helpfulness  \\\n0  To build an assistive device to help an elderl...            3   \n1  There are many different types of assistive de...            4   \n2  When deciding what technology to use to build ...            4   \n3  You can create an assistant device to help an ...            3   \n4  Hi there! I'm Dr. Family, and I'm here to tell...            3   \n\n   correctness  coherence  complexity  verbosity  \n0            4          4           2          2  \n1            3          3           2          3  \n2            4          4           2          2  \n3            3          3           2          3  \n4            3          3           2          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>response</th>\n      <th>helpfulness</th>\n      <th>correctness</th>\n      <th>coherence</th>\n      <th>complexity</th>\n      <th>verbosity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are the three most important things to co...</td>\n      <td>To build an assistive device to help an elderl...</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What are the three most important things to co...</td>\n      <td>There are many different types of assistive de...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What are the three most important things to co...</td>\n      <td>When deciding what technology to use to build ...</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What are the three most important things to co...</td>\n      <td>You can create an assistant device to help an ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Background:\\n&lt;start of reference&gt;\\nFamily doct...</td>\n      <td>Hi there! I'm Dr. Family, and I'm here to tell...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"validation_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:00.708508Z","iopub.execute_input":"2024-11-19T13:41:00.708918Z","iopub.status.idle":"2024-11-19T13:41:00.720441Z","shell.execute_reply.started":"2024-11-19T13:41:00.708864Z","shell.execute_reply":"2024-11-19T13:41:00.719647Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  The reference text below provides context for ...   \n1  The reference text below provides context for ...   \n2  The following information may be useful:\\n<sta...   \n3  The following information may be useful:\\n<sta...   \n4  The following information may be useful:\\n<sta...   \n\n                                            response  helpfulness  \\\n0  A woman who helped her cousin retrieve her bel...            3   \n1  A woman who tried to help her cousin retrieve ...            2   \n2  The protagonist has a very casual attitude tow...            3   \n3  The protagonist has a positive attitude toward...            3   \n4  The protagonist's attitude toward swear words ...            3   \n\n   correctness  coherence  complexity  verbosity  \n0            2          3           2          2  \n1            2          3           1          2  \n2            2          3           1          1  \n3            3          3           2          1  \n4            3          3           2          2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>response</th>\n      <th>helpfulness</th>\n      <th>correctness</th>\n      <th>coherence</th>\n      <th>complexity</th>\n      <th>verbosity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The reference text below provides context for ...</td>\n      <td>A woman who helped her cousin retrieve her bel...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The reference text below provides context for ...</td>\n      <td>A woman who tried to help her cousin retrieve ...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The following information may be useful:\\n&lt;sta...</td>\n      <td>The protagonist has a very casual attitude tow...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The following information may be useful:\\n&lt;sta...</td>\n      <td>The protagonist has a positive attitude toward...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The following information may be useful:\\n&lt;sta...</td>\n      <td>The protagonist's attitude toward swear words ...</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:00.721540Z","iopub.execute_input":"2024-11-19T13:41:00.721900Z","iopub.status.idle":"2024-11-19T13:41:00.768820Z","shell.execute_reply.started":"2024-11-19T13:41:00.721861Z","shell.execute_reply":"2024-11-19T13:41:00.767620Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 35331 entries, 0 to 35330\nData columns (total 7 columns):\n #   Column       Non-Null Count  Dtype \n---  ------       --------------  ----- \n 0   prompt       35331 non-null  object\n 1   response     35331 non-null  object\n 2   helpfulness  35331 non-null  int64 \n 3   correctness  35331 non-null  int64 \n 4   coherence    35331 non-null  int64 \n 5   complexity   35331 non-null  int64 \n 6   verbosity    35331 non-null  int64 \ndtypes: int64(5), object(2)\nmemory usage: 1.9+ MB\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_df[\"complexity\"].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:00.770227Z","iopub.execute_input":"2024-11-19T13:41:00.770673Z","iopub.status.idle":"2024-11-19T13:41:00.783767Z","shell.execute_reply.started":"2024-11-19T13:41:00.770619Z","shell.execute_reply":"2024-11-19T13:41:00.782562Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"count    35331.000000\nmean         1.443888\nstd          0.822268\nmin          0.000000\n25%          1.000000\n50%          1.000000\n75%          2.000000\nmax          4.000000\nName: complexity, dtype: float64"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"# 3.1 Objective\n\nDevelop a regression model capable of reasonably accurately predicting the complexity\nattribute of a response using the HelpSteer Dataset.","metadata":{}},{"cell_type":"markdown","source":"Use a small model like DistilBERT to extract embeddings from the prompt and response columns","metadata":{}},{"cell_type":"code","source":"import torch\n\n# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:00.805597Z","iopub.execute_input":"2024-11-19T13:41:00.805907Z","iopub.status.idle":"2024-11-19T13:41:00.817426Z","shell.execute_reply.started":"2024-11-19T13:41:00.805861Z","shell.execute_reply":"2024-11-19T13:41:00.816133Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, DistilBertModel\n\n# Load the model and tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)  # Move model to GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:00.821939Z","iopub.execute_input":"2024-11-19T13:41:00.822227Z","iopub.status.idle":"2024-11-19T13:41:07.178806Z","shell.execute_reply.started":"2024-11-19T13:41:00.822201Z","shell.execute_reply":"2024-11-19T13:41:07.178022Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66aec22c6ab34773b432c39ec1735894"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ae0ac563c854a7a9334bbccafacb028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6212607bdb9043f6b3a3812f226767cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f52812ccac54af5b43d5651e7c4afab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4ebf9fd1c2b44c7a76112a214e81524"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"997970d21d3243828fdee0a4ddae6b30"}},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":" Tokenize the input text, passes it through the model, and returns the embeddings","metadata":{}},{"cell_type":"code","source":"def get_embeddings(text):\n    # Tokenize the input text and send it to the GPU\n    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128).to(device)\n    \n    # Generate embeddings with no gradient tracking\n    with torch.no_grad():\n        outputs = model(**inputs)\n    \n    # Move embeddings back to CPU for further processing if necessary\n    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n    return embeddings\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:07.180040Z","iopub.execute_input":"2024-11-19T13:41:07.180493Z","iopub.status.idle":"2024-11-19T13:41:07.186080Z","shell.execute_reply.started":"2024-11-19T13:41:07.180465Z","shell.execute_reply":"2024-11-19T13:41:07.185195Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"Apply this function to both the prompt and response columns","metadata":{}},{"cell_type":"code","source":"train_df['prompt_embedding'] = train_df['prompt'].apply(get_embeddings)\ntrain_df['response_embedding'] = train_df['response'].apply(get_embeddings)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:41:07.187090Z","iopub.execute_input":"2024-11-19T13:41:07.187352Z","iopub.status.idle":"2024-11-19T13:52:44.243730Z","shell.execute_reply.started":"2024-11-19T13:41:07.187328Z","shell.execute_reply":"2024-11-19T13:52:44.242762Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import numpy as np\n\n# Average the prompt and response embeddings\ntrain_df['combined_embedding'] = train_df.apply(lambda row: (row['prompt_embedding'] + row['response_embedding']) , axis=1)\n\n\n# Prepare the feature matrix (X) and target variable (y)\nX = np.vstack(train_df['combined_embedding'].values)\ny = train_df['complexity'].values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:44.245003Z","iopub.execute_input":"2024-11-19T13:52:44.246088Z","iopub.status.idle":"2024-11-19T13:52:44.779211Z","shell.execute_reply.started":"2024-11-19T13:52:44.246043Z","shell.execute_reply":"2024-11-19T13:52:44.778431Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_df['combined_embedding']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:44.781392Z","iopub.execute_input":"2024-11-19T13:52:44.781640Z","iopub.status.idle":"2024-11-19T13:52:44.792545Z","shell.execute_reply.started":"2024-11-19T13:52:44.781616Z","shell.execute_reply":"2024-11-19T13:52:44.791579Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0        [-0.4473592, 0.56709456, 0.3154971, -0.0720754...\n1        [-0.5759791, 0.607692, 0.2765418, -0.09543538,...\n2        [-0.67710173, 0.4798023, 0.25830466, -0.029011...\n3        [-0.53883135, 0.4674706, 0.37658167, 0.0036770...\n4        [0.0087714195, 0.64115447, 0.36642605, -0.2480...\n                               ...                        \n35326    [-1.5298746, -0.370573, 0.47147185, -0.2574832...\n35327    [-0.47161123, 0.105901666, 0.08467649, -0.0057...\n35328    [-0.34656668, -0.09481117, 0.19014813, 0.02840...\n35329    [0.27400887, 0.114452496, 0.00477916, 0.052146...\n35330    [-0.39414436, -0.123563945, 0.34819585, 0.0215...\nName: combined_embedding, Length: 35331, dtype: object"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"train_df['combined_embedding'].info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:44.793648Z","iopub.execute_input":"2024-11-19T13:52:44.793899Z","iopub.status.idle":"2024-11-19T13:52:44.808967Z","shell.execute_reply.started":"2024-11-19T13:52:44.793876Z","shell.execute_reply":"2024-11-19T13:52:44.808125Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.series.Series'>\nRangeIndex: 35331 entries, 0 to 35330\nSeries name: combined_embedding\nNon-Null Count  Dtype \n--------------  ----- \n35331 non-null  object\ndtypes: object(1)\nmemory usage: 276.1+ KB\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"sample_embedding_shape = train_df['combined_embedding'].iloc[0].shape\nprint(\"Sample embedding shape:\", sample_embedding_shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:44.810105Z","iopub.execute_input":"2024-11-19T13:52:44.810407Z","iopub.status.idle":"2024-11-19T13:52:44.815878Z","shell.execute_reply.started":"2024-11-19T13:52:44.810373Z","shell.execute_reply":"2024-11-19T13:52:44.815111Z"}},"outputs":[{"name":"stdout","text":"Sample embedding shape: (768,)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# X is the feature matrix (e.g., combined embeddings), y is the target (complexity)\nX = np.vstack(train_df['combined_embedding'].values)  \ny = train_df['complexity'].values\n\n# Split the data into 80% training and 20% testing\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:44.816755Z","iopub.execute_input":"2024-11-19T13:52:44.817015Z","iopub.status.idle":"2024-11-19T13:52:45.373862Z","shell.execute_reply.started":"2024-11-19T13:52:44.816974Z","shell.execute_reply":"2024-11-19T13:52:45.372892Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"print(\"Training set:\", X_train.shape, y_train.shape)\nprint(\"Testing set:\", X_test.shape, y_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:45.375038Z","iopub.execute_input":"2024-11-19T13:52:45.375524Z","iopub.status.idle":"2024-11-19T13:52:45.380172Z","shell.execute_reply.started":"2024-11-19T13:52:45.375497Z","shell.execute_reply":"2024-11-19T13:52:45.379276Z"}},"outputs":[{"name":"stdout","text":"Training set: (28264, 768) (28264,)\nTesting set: (7067, 768) (7067,)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:45.381175Z","iopub.execute_input":"2024-11-19T13:52:45.381441Z","iopub.status.idle":"2024-11-19T13:52:45.389041Z","shell.execute_reply.started":"2024-11-19T13:52:45.381416Z","shell.execute_reply":"2024-11-19T13:52:45.388323Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(28264, 768)"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"# Bypass the Embedding Layer:\nThe custom model skips the embedding layer by directly accepting precomputed_embeddings in the forward method.\n# Regression Head: \nA single linear layer (self.regression_head) replaces the classification head to produce a continuous output for regression.\n# Forward Pass: \nThe model takes precomputed_embeddings and directly feeds them into the transformer layers","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom transformers import DistilBertModel, DistilBertConfig\n\n# Load the base DistilBERT model without the classification head\nbase_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n\n\nclass DistilBERTForRegression(nn.Module):\n    def __init__(self, base_model):\n        super(DistilBERTForRegression, self).__init__()\n        self.base_model = base_model  # DistilBERT base model\n        \n        # Regression head for single output\n        self.regression_head = nn.Linear(self.base_model.config.hidden_size, 1)\n\n    def forward(self, precomputed_embeddings):\n        # Expand embeddings to [batch_size, 512, 768]\n        batch_size = precomputed_embeddings.size(0)\n        expanded_embeddings = precomputed_embeddings.unsqueeze(1).expand(batch_size, 512, 768)\n        \n        # Pass expanded embeddings to the transformer layers\n        transformer_output = self.base_model(inputs_embeds=expanded_embeddings)\n        pooled_output = transformer_output.last_hidden_state[:, 0]  # CLS token representation\n        return self.regression_head(pooled_output)  # Output continuous value for regression\n\n\n\n# Instantiate the custom model\nregression_model = DistilBERTForRegression(base_model).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:45.389982Z","iopub.execute_input":"2024-11-19T13:52:45.390253Z","iopub.status.idle":"2024-11-19T13:52:46.008429Z","shell.execute_reply.started":"2024-11-19T13:52:45.390211Z","shell.execute_reply":"2024-11-19T13:52:46.007469Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Convert data to tensors and create a DataLoader\ntrain_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\n# Define optimizer and loss function\noptimizer = optim.Adam(regression_model.parameters(), lr=2e-5)\ncriterion = nn.MSELoss()  # MSE for regression\n\n# Training loop\nepochs = 3\nregression_model.train()  # Set model to training mode\n\nfor epoch in range(epochs):\n    total_loss = 0\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    \n    # Wrap the training loop with tqdm for a progress bar\n    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n        optimizer.zero_grad()\n        \n        # Move inputs and targets to device\n        inputs, targets = batch[0].to(device), batch[1].to(device)\n        \n        # Forward pass\n        outputs = regression_model(inputs)\n        loss = criterion(outputs.squeeze(), targets)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Print average loss for the epoch\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Average Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T13:52:46.009671Z","iopub.execute_input":"2024-11-19T13:52:46.010048Z","iopub.status.idle":"2024-11-19T14:30:42.241357Z","shell.execute_reply.started":"2024-11-19T13:52:46.010009Z","shell.execute_reply":"2024-11-19T14:30:42.240549Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.5300\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.4939\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.4587\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tqdm import tqdm\nimport numpy as np\n\n# Convert test data to tensors and create a DataLoader\ntest_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Set model to evaluation mode\nregression_model.eval()\n\n# Initialize lists to store predictions and actual values\nall_predictions = []\nall_targets = []\n\n# Disable gradient computation for evaluation\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n        # Move inputs and targets to device\n        inputs, targets = batch[0].to(device), batch[1].to(device)\n        \n        # Forward pass to get predictions\n        outputs = regression_model(inputs)\n        \n        # Store predictions and actual targets\n        all_predictions.extend(outputs.squeeze().cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n\n# Calculate RMSE and MAE\nrmse = mean_squared_error(all_targets, all_predictions, squared=False)  # RMSE\nmae = mean_absolute_error(all_targets, all_predictions)\n\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T14:30:42.242669Z","iopub.execute_input":"2024-11-19T14:30:42.243573Z","iopub.status.idle":"2024-11-19T14:31:44.091837Z","shell.execute_reply.started":"2024-11-19T14:30:42.243530Z","shell.execute_reply":"2024-11-19T14:31:44.090817Z"}},"outputs":[{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"RMSE: 0.6840\nMAE: 0.5442\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Convert data to tensors and create a DataLoader\ntrain_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# Define optimizer and loss function\noptimizer = optim.Adam(regression_model.parameters(), lr=1e-5)\ncriterion = nn.MSELoss()  # MSE for regression\n\n# Training loop\nepochs = 3\nregression_model.train()  # Set model to training mode\n\nfor epoch in range(epochs):\n    total_loss = 0\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    \n    # Wrap the training loop with tqdm for a progress bar\n    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n        optimizer.zero_grad()\n        \n        # Move inputs and targets to device\n        inputs, targets = batch[0].to(device), batch[1].to(device)\n        \n        # Forward pass\n        outputs = regression_model(inputs)\n        loss = criterion(outputs.squeeze(), targets)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Print average loss for the epoch\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Average Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T14:31:44.093153Z","iopub.execute_input":"2024-11-19T14:31:44.093512Z","iopub.status.idle":"2024-11-19T15:08:38.940390Z","shell.execute_reply.started":"2024-11-19T14:31:44.093474Z","shell.execute_reply":"2024-11-19T15:08:38.939538Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.3642\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.3041\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"                                                           ","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.2488\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tqdm import tqdm\nimport numpy as np\n\n# Convert test data to tensors and create a DataLoader\ntest_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Set model to evaluation mode\nregression_model.eval()\n\n# Initialize lists to store predictions and actual values\nall_predictions = []\nall_targets = []\n\n# Disable gradient computation for evaluation\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n        # Move inputs and targets to device\n        inputs, targets = batch[0].to(device), batch[1].to(device)\n        \n        # Forward pass to get predictions\n        outputs = regression_model(inputs)\n        \n        # Store predictions and actual targets\n        all_predictions.extend(outputs.squeeze().cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n\n# Calculate RMSE and MAE\nrmse = mean_squared_error(all_targets, all_predictions, squared=False)  # RMSE\nmae = mean_absolute_error(all_targets, all_predictions)\n\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:08:38.941601Z","iopub.execute_input":"2024-11-19T15:08:38.941972Z","iopub.status.idle":"2024-11-19T15:09:40.867813Z","shell.execute_reply.started":"2024-11-19T15:08:38.941918Z","shell.execute_reply":"2024-11-19T15:09:40.866921Z"}},"outputs":[{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"RMSE: 0.6308\nMAE: 0.4916\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from tqdm import tqdm\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Convert data to tensors and create a DataLoader\ntrain_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# Define optimizer and loss function\noptimizer = optim.Adam(regression_model.parameters(), lr=2e-2)\ncriterion = nn.MSELoss()  # MSE for regression\n\n# Training loop\nepochs = 3\nregression_model.train()  # Set model to training mode\n\nfor epoch in range(epochs):\n    total_loss = 0\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    \n    # Wrap the training loop with tqdm for a progress bar\n    for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n        optimizer.zero_grad()\n        \n        # Move inputs and targets to device\n        inputs, targets = batch[0].to(device), batch[1].to(device)\n        \n        # Forward pass\n        outputs = regression_model(inputs)\n        loss = criterion(outputs.squeeze(), targets)\n        \n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    # Print average loss for the epoch\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Average Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:09:41.019118Z","iopub.execute_input":"2024-11-19T15:09:41.019338Z","iopub.status.idle":"2024-11-19T15:46:40.640049Z","shell.execute_reply.started":"2024-11-19T15:09:41.019315Z","shell.execute_reply":"2024-11-19T15:46:40.639011Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Average Loss: 1.1728\nEpoch 2/3\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.6980\nEpoch 3/3\n","output_type":"stream"},{"name":"stderr","text":"                                                           ","output_type":"stream"},{"name":"stdout","text":"Average Loss: 0.6935\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"from torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tqdm import tqdm\nimport numpy as np\n\n# Convert test data to tensors and create a DataLoader\ntest_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\n# Set model to evaluation mode\nregression_model.eval()\n\n# Initialize lists to store predictions and actual values\nall_predictions = []\nall_targets = []\n\n# Disable gradient computation for evaluation\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n        # Move inputs and targets to device\n        inputs, targets = batch[0].to(device), batch[1].to(device)\n        \n        # Forward pass to get predictions\n        outputs = regression_model(inputs)\n        \n        # Store predictions and actual targets\n        all_predictions.extend(outputs.squeeze().cpu().numpy())\n        all_targets.extend(targets.cpu().numpy())\n\n# Calculate RMSE and MAE\nrmse = mean_squared_error(all_targets, all_predictions, squared=False)  # RMSE\nmae = mean_absolute_error(all_targets, all_predictions)\n\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T15:46:40.641482Z","iopub.execute_input":"2024-11-19T15:46:40.641759Z","iopub.status.idle":"2024-11-19T15:47:42.674230Z","shell.execute_reply.started":"2024-11-19T15:46:40.641733Z","shell.execute_reply":"2024-11-19T15:47:42.673340Z"}},"outputs":[{"name":"stderr","text":"                                                             ","output_type":"stream"},{"name":"stdout","text":"RMSE: 0.8245\nMAE: 0.7105\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":39}]}